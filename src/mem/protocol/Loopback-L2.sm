machine(MachineType:L2Cache, "Loopback L2 Cache") :
    DirectoryMemory *directory;
    CacheMemory * L2cache;
    Cycles l2_request_latency := 50;
    Cycles l2_response_latency := 20;

    /* DMA */
    //MessageBuffer * requestFromDMA, network="From", virtual_network="1", vnet_type="request";
    //MessageBuffer * responseToDMA, network="To", virtual_network="3", vnet_type="request";

    /* CORES */
    MessageBuffer * requestFromL1, network="From", virtual_network="1", vnet_type="request";
    MessageBuffer * responseToL1, network="To", virtual_network="3", vnet_type="response";

    // Still don't know what this is for
    //MessageBuffer * triggerQueue;

    /* Memory */
    MessageBuffer *requestToMemory;
    MessageBuffer *responseFromMemory;
{
    // Used to for functions that would be static outside of SLICC
    WriteMask static_WriteMask;

    /*******************************STATES*************************************/
    state_declaration(State, desc="Primary Cache States", default="L2Cache_State_I") {
        I, AccessPermission:Invalid, desc="Invalid, not cached";
        V, AccessPermission:Read_Only ,desc="Valid, cached"; 
    }

    /*******************************EVENTS*************************************/
    enumeration(Event, desc="Cache Events") {
        ReqV,       desc="Process request for data";
        ReqWB_L2,   desc="Process request for data WB to L2";
        //DmaRead,    desc="DMA Read request";
        //DmaWrite,   desc="DMA Write request";
    }

    /***************************STRUCTURES*************************************/
    structure(StateVec, external="yes", desc="...") {
         void   setAt(int, State),      desc="...";
         State  getAt(int),             desc="...";
         bool   contains(State),        desc="...";
         int    getSize(),              desc="...";
    }

    structure(Entry, desc="...", interface="AbstractCacheEntry") {
        StateVec WordStates,           desc="cache state";
        bool Dirty,                 desc="Is the data dirty (diff than memory)?";
        DataBlock DataBlk,          desc="data for the block";
        WriteMask writeMask, desc="written bytes masks";
    }

    structure(DirEntry, desc="Directory Entry", interface="AbstractEntry") {
        StateVec DirState,  desc="Dir state";
        DataBlock DataBlk,  desc="Data block";
    }

    structure(TBE, desc="...") {
        StateVec WordStates,    desc="Transient state";
        DataBlock DataBlk, desc="data for the block, required for concurrent writebacks";
        bool Dirty,        desc="Is the data dirty (different than memory)?";
        int NumPendingMsgs,desc="Number of acks/data messages that this processor is waiting for";
        bool Shared,       desc="Victim hit by shared probe";
     }

    structure(TBETable, external="yes") {
        TBE lookup(Addr);
        void allocate(Addr);
        void deallocate(Addr);
        bool isPresent(Addr);
    }

    TBETable TBEs, template="<L2Cache_TBE>", constructor="m_number_of_TBEs";
    int L2C_select_low_bit, default="RubySystem::getBlockSizeBits()";

    
    void set_cache_entry(AbstractCacheEntry b);
    void unset_cache_entry();

    /********************INTERNAL FUNCTIONS************************************/
    //Taken from GPU_VIPER-TCP
    //
    Tick clockEdge();
    Entry getCacheEntry(Addr address), return_by_pointer="yes" {
        Entry cache_entry := static_cast(Entry, "pointer", L2cache.lookup(address));
        if (is_valid(cache_entry)) {
            return cache_entry;
        }
        cache_entry := static_cast(Entry, "pointer", L2cache.allocate(address, new Entry));
        return cache_entry;
    }

    void functionalRead(Addr addr, Packet *pkt) {
        TBE tbe := TBEs.lookup(addr);
        if(is_valid(tbe)) {
            testAndRead(addr, tbe.DataBlk, pkt);
        } else {
            functionalMemoryRead(pkt);
        }
    }

    int functionalWrite(Addr addr, Packet *pkt) {
        int num_functional_writes := 0;

        TBE tbe := TBEs.lookup(addr);
        if(is_valid(tbe)) {
            num_functional_writes := num_functional_writes +
                testAndWrite(addr, tbe.DataBlk, pkt);
        }

        num_functional_writes := num_functional_writes +
            functionalMemoryWrite(pkt);
        return num_functional_writes;
    }

    AccessPermission getAccessPermission(Addr addr) {
        //TBE tbe := TBEs.lookup(addr);
        //if(is_valid(tbe)) {
        //    return L1Cache_State_to_permission(tbe.TBEState);
        //}

        //Entry cache_entry := getCacheEntry(addr);
        //if(is_valid(cache_entry)) {
        //    return L1Cache_State_to_permission(cache_entry.CacheState);
        //}

        return AccessPermission:NotPresent;
    }

    State getState(TBE tbe, Entry cache_entry, Addr addr) {
        int idx := static_WriteMask.getWordOffset(addr);
        if (is_valid(cache_entry)) {
            return static_cast(State, "state", cache_entry.WordStates.getAt(idx));
        } else if (is_valid(tbe)) {
            return static_cast(State, "state", tbe.WordStates.getAt(idx));
        }
        return State:I;
    }

    void setState(TBE tbe, Entry cache_entry, Addr addr, State state) {
        int idx := static_WriteMask.getWordOffset(addr);
        if (is_valid(tbe)) {
            tbe.WordStates.setAt(idx, state);
        }

        if (is_valid(cache_entry)) {
            cache_entry.WordStates.setAt(idx, state);
        }
    }

    void setAccessPermission(Entry cache_entry, Addr addr, State state) {
        //if (is_valid(cache_entry)) {
        //    cache_entry.changePermission(L1Cache_State_to_permission(state)tbe
    }

    DirEntry getDirectoryEntry(Addr addr), return_by_pointer="yes" {
        DirEntry dir_entry := static_cast(DirEntry, "pointer", directory.lookup(addr));
        if (is_valid(dir_entry)) {
            return dir_entry;
        }
        dir_entry := static_cast(DirEntry, "pointer", directory.allocate(addr, new DirEntry));
        return dir_entry;
    }


    /***************************IN PORT****************************************/
    //in_port(dmaRequestQueue_in, DMARequestMsg, requestFromDMA) {
    //  if (dmaRequestQueue_in.isReady(clockEdge())) {
    //    peek(dmaRequestQueue_in, DMARequestMsg) {
    //      TBE tbe := TBEs.lookup(in_msg.LineAddress);
    //      CacheEntry entry := getCacheEntry(in_msg.LineAddress);
    //      WriteMask tmp;
    //      tmp.fillMask();
    //      if (in_msg.Type == DMARequestType:READ) {
    //        triggerLine(Event:DmaRead, in_msg.LineAddress, entry, tbe, tmp);
    //      } else if (in_msg.Type == DMARequestType:WRITE) {
    //        triggerLine(Event:DmaWrite, in_msg.LineAddress, entry, tbe, tmp);
    //      } else {
    //        error("Unknown DMA msg");
    //      }
    //    }
    //  }
    //}

    in_port(memQueue_in, MemoryMsg, responseFromMemory) {
        if (memQueue_in.isReady(clockEdge())) {
            peek(memQueue_in, MemoryMsg) {
                //TBE tbe := TBEs.lookup(in_msg.addr);
                //Entry entry := static_cast(Entry, "pointer", L2cache.lookup(in_msg.addr));
                //if (in_msg.Type == MemoryRequestType:MEMORY_READ) {
                //    trigger(Event:MemData, in_msg.addr, entry, tbe);
                //    DPRINTF(RubySlicc, "%s\n", in_msg);
                //} else if (in_msg.Type == MemoryRequestType:MEMORY_WB) {
                //    trigger(Event:WBAck, in_msg.addr, entry, tbe); // ignore WBAcks, don't care about them.
                //} else {
                    DPRINTF(RubySlicc, "%s\n", in_msg.Type);
                    error("Invalid message");
                //}
            }
        }
    }

    in_port(requestFromL1_in, RequestMsg, requestFromL1, desc="In-port for requests from L1") {
        if (requestFromL1_in.isReady(clockEdge())) {
            peek(requestFromL1_in, RequestMsg, block_on="Address") {
                Entry cache_entry := getCacheEntry(in_msg.Address);
                TBE tbe := TBEs.lookup(in_msg.Address);
                if (in_msg.Type == CoherenceRequestType:ReqV) {
                    //DPRINTF(WHD, "ReqV MSG: %s\n",in_msg);
                    triggerLine(Event:ReqV, in_msg.Address, cache_entry, tbe, in_msg.bitMask);
                }else if (in_msg.Type == CoherenceRequestType:ReqWB_L2) {
                    triggerLine(Event:ReqWB_L2, in_msg.Address, cache_entry, tbe, in_msg.bitMask);
                } else {
                    error("Unexpected Response Message to Core");
                }
            }
        }
    }   

    /**************************OUT PORT****************************************/
    //out_port(dmaResponseQueue_out, DMAResponseMsg, responseToDMA);
    out_port(responseToCore_out, ResponseMsg, responseToL1);
    out_port(memQueue_out, MemoryMsg, requestToMemory);

    /**********************************ACTIONS********************************/
    action(p_popRequestFromL1, "pr", desc="Pop L1 request queue") {
        if (action_mask.isFirstValid(address)) {
            peek_dangerous(requestFromL1_in, RequestMsg) {
                in_msg.bitMask.unsetMask(action_mask);
                if (in_msg.bitMask.isEmpty()) {
                    requestFromL1_in.dequeue(clockEdge());
                }
            }
        }
    }

    action(rsp_respondOdata, "rspOdata", desc="Generate response to reqOdata") {
        peek(requestFromL1_in, RequestMsg) {
            enqueue(responseToCore_out, ResponseMsg, l2_request_latency) {
                out_msg.Address := address;
                out_msg.Type := CoherenceResponseType:RspOdata;
                out_msg.Sender := machineID;
                out_msg.DataBlk := cache_entry.DataBlk;
                out_msg.Destination.add(in_msg.Requestor);
                out_msg.MessageSize := MessageSizeType:ResponseL2hit_Data;
            }
        }
    }

    action(rsp_respondV, "rspV", desc="Generate response to reqV") {
        if (action_mask.isFirstValid(address)) {
            peek(requestFromL1_in, RequestMsg) {
                enqueue(responseToCore_out, ResponseMsg, l2_request_latency) {
                    out_msg.Address := in_msg.Address;
                    out_msg.Type := CoherenceResponseType:RspV;
                    out_msg.Sender := machineID;
                    out_msg.DataBlk.copyPartial(cache_entry.DataBlk, action_mask);
                    out_msg.Destination.add(in_msg.Requestor);
                    out_msg.MessageSize := MessageSizeType:ResponseL2hit_Data;
                    out_msg.bitMask.cpyMask(action_mask);
                }
                L2cache.deallocate(in_msg.Address);
                unset_cache_entry();
            }
        }
    }

    action(rsp_respondWB_L2, "rspWB_L2", desc="Generate response to reqWB_L2") {
        peek(requestFromL1_in, RequestMsg) {
            enqueue(responseToCore_out, ResponseMsg, l2_request_latency) {
                out_msg.Address := address;
                out_msg.Type := CoherenceResponseType:RspWB_L2;
                out_msg.Sender := machineID;
                out_msg.Destination.add(in_msg.Requestor);
                out_msg.MessageSize := MessageSizeType:Response_Control;
            }
        }
    }

    action(s_storeDone, "s", desc="local store done") {
        assert(is_valid(cache_entry));
        if (action_mask.isFirstValid(address)) {
            peek(requestFromL1_in, RequestMsg) {
                cache_entry.DataBlk.copyPartial(in_msg.DataBlk, action_mask);
                cache_entry.writeMask.orMask(action_mask);
                cache_entry.Dirty := true;
            }
        }
    }

    /* DMA ACTIONS */
    //action(p_popRequestFromDMA, "prDMA", desc="Pop DMA request queue") {
    //    if (action_mask.isFirstValid(address)) {
    //        peek_dangerous(dmaRequestQueue_in, DMARequestMsg) {
    //            // Following lines can be ignored because we assume line only for DMA
    //            //in_msg.bitMask.unsetMask(action_mask);
    //            //if (in_msg.bitMask.isEmpty()) {
    //            requestFromL1_in.dequeue(clockEdge());
    //            //}
    //        }
    //    }
    //}

    //action(rsp_dmaV, "rsp_dmaV", desc="Generate response to dma read req") {
    //    if (action_mask.isFirstValid(address)) {
    //        peek (dmaRequestQueue_in, DMARequestMsg) {
    //            DataBlock db_tmp;
    //            db_tmp.copyPartial(cache_entry.DataBlk, action_mask);
    //            enqueue(dmaResponseQueue_out, DMAResponseMsg) {
    //                out_msg.Address := address;
    //                
    //            }
    //        }
    //    }
    //}

   /***************************TRANSITIONS************************************/
    transition(I, ReqV) {
        rsp_respondV;
        p_popRequestFromL1;
    }

    transition(I, ReqWB_L2, V) {
        s_storeDone;
        rsp_respondWB_L2;
        p_popRequestFromL1;
    }

    //transition(I, DmaRead) {
    //    rsp_dmaV;
    //    p_popRequestFromDMA;
    //}

    //transition(I, DmaWrite) {
    //    s_storeDone;
    //    rsp_dmaW;
    //    p_popRequestFromDMA;
    //}
/*
    transition(V, ReqV) {
    
    }

    // This is not really implemented yet, but I need to think about inclusiveness
    transition(V, ReqWB_L2) {
    
    }
*/
}
